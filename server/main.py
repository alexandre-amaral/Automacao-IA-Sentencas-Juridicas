from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi import UploadFile, File, HTTPException
from fastapi import status
from fastapi.responses import FileResponse
from pydantic import BaseModel
from dotenv import load_dotenv
import os
import logging
from uuid import uuid4
from pathlib import Path
from typing import Optional, Dict

# Configurar logging detalhado
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Parsing libs
try:
    import fitz  # PyMuPDF
except Exception:  # pragma: no cover
    fitz = None
try:
    from docx import Document  # python-docx
except Exception:  # pragma: no cover
    Document = None

# Carrega vari√°veis de ambiente
load_dotenv()

# Inicializa a aplica√ß√£o FastAPI
app = FastAPI(
    title="Sistema de Automa√ß√£o de Senten√ßas Judiciais",
    description="API para automatizar a gera√ß√£o de senten√ßas judiciais com IA",
    version="1.0.0"
)

# Configura√ß√£o do CORS para permitir requisi√ß√µes do frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Permitir todas as origens temporariamente
    allow_credentials=False,  # Desabilitar credentials para simplificar
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"],
)

STORAGE_DIR = Path(__file__).resolve().parent / "storage"
STORAGE_DIR.mkdir(parents=True, exist_ok=True)

ALLOWED_PROCESSO = {"pdf", "docx"}
ALLOWED_AUDIENCIA = {"mp4", "mp3", "wav", "m4a", "aac"}

class UploadResponse(BaseModel):
    case_id: str
    files: Dict[str, Optional[str]]

class ProcessingResponse(BaseModel):
    case_id: str
    step: str
    status: str
    message: str

@app.get("/")
async def root():
    """Endpoint raiz da API"""
    return {
        "message": "Sistema de Automa√ß√£o de Senten√ßas Judiciais",
        "status": "online",
        "version": "1.0.0"
    }

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {"status": "healthy"}

@app.post("/upload-caso", response_model=UploadResponse, status_code=status.HTTP_201_CREATED)
async def upload_caso(
    processo: Optional[UploadFile] = File(default=None, description="PDF/DOCX do processo"),
    audiencia: Optional[UploadFile] = File(default=None, description="MP4 da audi√™ncia")
):
    """Recebe upload de 1 arquivo de processo (PDF/DOCX) e 1 de audi√™ncia (MP4)"""
    logger.info("üöÄ INICIANDO UPLOAD DE CASO")
    
    if processo is None and audiencia is None:
        logger.error("‚ùå Nenhum arquivo enviado")
        raise HTTPException(status_code=400, detail="Envie ao menos um arquivo: processo e/ou audi√™ncia")

    case_id = str(uuid4())
    case_dir = STORAGE_DIR / case_id
    case_dir.mkdir(parents=True, exist_ok=True)
    
    logger.info(f"üìÅ Case ID gerado: {case_id}")
    logger.info(f"üìÇ Diret√≥rio criado: {case_dir}")

    saved_processo = None
    saved_audiencia = None

    # Salvar processo
    if processo is not None:
        logger.info(f"üìÑ Processando arquivo: {processo.filename}")
        proc_ext = (processo.filename or "").split(".")[-1].lower()
        if proc_ext not in ALLOWED_PROCESSO:
            logger.error(f"‚ùå Extens√£o inv√°lida do processo: .{proc_ext}")
            raise HTTPException(status_code=400, detail=f"Extens√£o do processo inv√°lida: .{proc_ext}")
        proc_path = case_dir / f"processo.{proc_ext}"
        data = await processo.read()
        proc_path.write_bytes(data)
        saved_processo = str(proc_path)
        logger.info(f"‚úÖ Processo salvo: {proc_path} ({len(data)} bytes)")

    # Salvar audi√™ncia
    if audiencia is not None:
        logger.info(f"üé• Processando audi√™ncia: {audiencia.filename}")
        aud_ext = (audiencia.filename or "").split(".")[-1].lower()
        if aud_ext not in ALLOWED_AUDIENCIA:
            logger.error(f"‚ùå Extens√£o inv√°lida da audi√™ncia: .{aud_ext}")
            raise HTTPException(status_code=400, detail=f"Extens√£o da audi√™ncia inv√°lida: .{aud_ext}")
        aud_path = case_dir / f"audiencia.{aud_ext}"
        data = await audiencia.read()
        aud_path.write_bytes(data)
        saved_audiencia = str(aud_path)
        logger.info(f"‚úÖ Audi√™ncia salva: {aud_path} ({len(data)} bytes)")

    logger.info(f"üéâ UPLOAD CONCLU√çDO! Case ID: {case_id}")
    
    # üöÄ INICIAR PIPELINE AUTOM√ÅTICO
    logger.info("üîÑ Iniciando pipeline autom√°tico...")
    
    try:
        # ETAPA 1: Transcri√ß√£o autom√°tica
        if saved_audiencia:
            logger.info("üìù Executando Etapa 1: Transcri√ß√£o...")
            await executar_transcricao_automatica(case_id)
        
        # ETAPA 2: Processamento Gemini autom√°tico  
        logger.info("üß† Executando Etapa 2: Processamento Gemini...")
        await executar_processamento_automatico(case_id)
        
        # ETAPA 3: Gera√ß√£o Claude autom√°tica
        logger.info("‚úçÔ∏è Executando Etapa 3: Gera√ß√£o de Senten√ßa...")
        await executar_geracao_automatica(case_id)
        
        logger.info("üéâ PIPELINE AUTOM√ÅTICO CONCLU√çDO!")
        
    except Exception as e:
        logger.error(f"‚ùå Erro no pipeline autom√°tico: {str(e)}")
        # Continua e retorna o case_id mesmo se houver erro

    return UploadResponse(case_id=case_id, files={"processo": saved_processo, "audiencia": saved_audiencia})

# ü§ñ FUN√á√ïES AUXILIARES PARA PIPELINE AUTOM√ÅTICO
async def executar_transcricao_automatica(case_id: str):
    """Executa transcri√ß√£o automaticamente"""
    from services.whisper_service import WhisperService
    
    case_dir = STORAGE_DIR / case_id
    
    # Encontrar arquivo de √°udio
    audio_file = None
    for ext in ALLOWED_AUDIENCIA:
        audio_path = case_dir / f"audiencia.{ext}"
        if audio_path.exists():
            audio_file = audio_path
            break
    
    if not audio_file:
        logger.warning("‚ö†Ô∏è Nenhum arquivo de √°udio encontrado para transcri√ß√£o")
        return
    
    # Verificar tamanho e processar
    tamanho_mb = audio_file.stat().st_size / (1024 * 1024)
    logger.info(f"üìè Tamanho do arquivo: {tamanho_mb:.1f}MB")
    
    arquivo_para_transcricao = audio_file
    
    if tamanho_mb > 25:
        logger.info(f"üîÑ Arquivo muito grande ({tamanho_mb:.1f}MB). Extraindo √°udio comprimido...")
        import subprocess
        
        audio_comprimido = case_dir / "audio_temp.mp3"
        comando = [
            'ffmpeg', '-i', str(audio_file),
            '-vn', '-acodec', 'mp3', '-ab', '64k', '-ar', '16000', '-y',
            str(audio_comprimido)
        ]
        
        resultado = subprocess.run(comando, capture_output=True, text=True)
        if resultado.returncode == 0:
            arquivo_para_transcricao = audio_comprimido
            logger.info(f"‚úÖ √Åudio comprimido: {arquivo_para_transcricao.stat().st_size / (1024 * 1024):.1f}MB")
    
    # Transcrever
    whisper_service = WhisperService()
    transcricao = whisper_service.transcrever_audiencia(arquivo_para_transcricao, case_id)
    whisper_service.salvar_transcricao(transcricao, case_dir)
    
    # Limpar tempor√°rio
    if arquivo_para_transcricao != audio_file and arquivo_para_transcricao.exists():
        arquivo_para_transcricao.unlink()
    
    logger.info(f"‚úÖ Transcri√ß√£o autom√°tica conclu√≠da: {len(transcricao.texto_completo)} caracteres")

async def executar_processamento_automatico(case_id: str):
    """Executa processamento Gemini automaticamente"""
    from services.gemini_processor import GeminiProcessor
    from services.rag_service import RAGService
    from services.whisper_service import TranscricaoAudiencia, WhisperService
    
    case_dir = STORAGE_DIR / case_id
    
    # Processar documento
    gemini_processor = GeminiProcessor()
    
    # Encontrar processo
    processo_path = None
    for ext in ALLOWED_PROCESSO:
        proc_path = case_dir / f"processo.{ext}"
        if proc_path.exists():
            processo_path = proc_path
            break
    
    if not processo_path:
        raise Exception("Documento do processo n√£o encontrado")
    
    # Extrair texto
    if processo_path.suffix.lower() == '.pdf':
        doc = fitz.open(str(processo_path))
        texto_processo = ""
        for page in doc:
            texto_processo += page.get_text("text") + "\n"
        doc.close()
    else:  # DOCX
        doc = Document(str(processo_path))
        texto_processo = '\n'.join([par.text for par in doc.paragraphs if par.text.strip()])
    
    logger.info(f"‚úÖ Texto extra√≠do: {len(texto_processo)} caracteres")
    
    # Limitar se muito grande
    if len(texto_processo) > 1500000:
        texto_processo = texto_processo[:1500000] + "... [TEXTO TRUNCADO - MUITO GRANDE]"
        logger.info("‚úÇÔ∏è Texto truncado para 1.5M caracteres")
    
    # Salvar texto extra√≠do para uso posterior no di√°logo inteligente
    texto_extraido_path = case_dir / "processo_extraido.txt"
    texto_extraido_path.write_text(texto_processo, encoding='utf-8')
    logger.info(f"üíæ Texto do processo salvo: {texto_extraido_path}")
    
    # Processar com Gemini
    processo_estruturado = gemini_processor.extrair_informacoes_processo(texto_processo)
    logger.info(f"‚úÖ Processamento Gemini conclu√≠do: {processo_estruturado.numero_processo}")
    
    # Processar transcri√ß√£o se existir
    transcricao_path = case_dir / "audiencia_transcricao.txt"
    analise_audiencia = None
    if transcricao_path.exists():
        transcricao_texto = transcricao_path.read_text(encoding='utf-8')
        transcricao_mock = TranscricaoAudiencia(
            texto_completo=transcricao_texto,
            duracao_segundos=None,
            idioma_detectado='pt',
            confianca=None,
            segmentos=None,
            metadados={}
        )
        whisper_service = WhisperService()
        analise_audiencia = whisper_service.processar_audiencia_com_gemini(transcricao_mock, case_id)
    
    # Salvar no RAG
    rag_service = RAGService()
    rag_service.salvar_conhecimento_caso(processo_estruturado, analise_audiencia, case_id)
    logger.info("‚úÖ Processamento autom√°tico conclu√≠do e salvo no RAG")

async def executar_geracao_automatica(case_id: str):
    """Executa gera√ß√£o de senten√ßa usando DI√ÅLOGO INTELIGENTE com prompt base estruturado"""
    from services.intelligent_dialogue_service import IntelligentDialogueService
    import json
    
    case_dir = STORAGE_DIR / case_id
    
    logger.info(f"üß† [{case_id}] INICIANDO DI√ÅLOGO INTELIGENTE (3 ETAPAS ESTRUTURADAS)")
    
    try:
        # Recuperar texto do processo
        processo_path = case_dir / "processo_extraido.txt"
        if not processo_path.exists():
            logger.warning(f"‚ö†Ô∏è [{case_id}] Texto do processo n√£o encontrado")
            return
        
        texto_processo = processo_path.read_text(encoding='utf-8')
        logger.info(f"üìÑ Texto do processo carregado: {len(texto_processo)} caracteres")
        
        # Recuperar transcri√ß√£o da audi√™ncia (opcional)
        transcricao_audiencia = None
        transcricao_path = case_dir / "transcricao.json"
        
        if transcricao_path.exists():
            transcricao_data = json.loads(transcricao_path.read_text(encoding='utf-8'))
            transcricao_audiencia = transcricao_data.get('texto_completo', '')
            logger.info(f"üé§ Transcri√ß√£o carregada: {len(transcricao_audiencia)} caracteres")
        
        # Executar di√°logo inteligente com prompt base estruturado
        # NOVA ABORDAGEM SECTORIAL para senten√ßas detalhadas
        dialogue_service = IntelligentDialogueService(case_id)
        resultado_completo = dialogue_service.executar_dialogo_completo(
            texto_processo=texto_processo,
            transcricao_audiencia=transcricao_audiencia
        )
        
        logger.info(f"‚úÖ DI√ÅLOGO INTELIGENTE CONCLU√çDO - {len(resultado_completo['etapas_executadas'])} etapas")
        
        # Salvar resultado completo estruturado
        resultado_path = case_dir / "dialogo_resultado_completo.json"
        resultado_path.write_text(
            json.dumps(resultado_completo, indent=2, ensure_ascii=False),
            encoding='utf-8'
        )
        
        # Salvar senten√ßa final
        sentenca_final = resultado_completo.get("sentenca_final", "")
        if sentenca_final:
            sentenca_path = case_dir / "sentenca_gerada.txt"
            sentenca_path.write_text(sentenca_final, encoding='utf-8')
            logger.info(f"üìù Senten√ßa gerada com PROMPT BASE: {len(sentenca_final)} caracteres")
        
        logger.info(f"üéâ [{case_id}] GERA√á√ÉO AUTOM√ÅTICA COMPLETA COM PROMPT BASE ESTRUTURADO")
        
    except Exception as e:
        logger.error(f"‚ùå Erro na gera√ß√£o com di√°logo inteligente: {str(e)}")
        raise

# ETAPA 1: Transcrever √°udio com Whisper
@app.post("/step1-transcribe/{case_id}", response_model=ProcessingResponse)
async def step1_transcribe_audio(case_id: str):
    """ETAPA 1: Transcreve √°udio da audi√™ncia usando Whisper"""
    logger.info(f"üé§ INICIANDO ETAPA 1 - TRANSCRI√á√ÉO WHISPER - Case ID: {case_id}")
    
    from services.whisper_service import WhisperService
    
    case_dir = STORAGE_DIR / case_id
    if not case_dir.exists():
        logger.error(f"‚ùå Case ID n√£o encontrado: {case_id}")
        raise HTTPException(status_code=404, detail="case_id n√£o encontrado")
    
    logger.info(f"üìÇ Diret√≥rio encontrado: {case_dir}")
    
    try:
        # Encontrar arquivo de √°udio
        logger.info("üîç Procurando arquivo de √°udio...")
        audio_file = None
        for ext in ALLOWED_AUDIENCIA:
            audio_path = case_dir / f"audiencia.{ext}"
            logger.info(f"   Verificando: {audio_path}")
            if audio_path.exists():
                audio_file = audio_path
                logger.info(f"‚úÖ Arquivo de √°udio encontrado: {audio_file}")
                break
        
        if not audio_file:
            logger.error("‚ùå Nenhum arquivo de √°udio encontrado")
            raise HTTPException(status_code=404, detail="Arquivo de √°udio n√£o encontrado")
        
        # Verificar tamanho do arquivo
        tamanho_mb = audio_file.stat().st_size / (1024 * 1024)
        logger.info(f"üìè Tamanho do arquivo: {tamanho_mb:.1f}MB")
        
        arquivo_para_transcricao = audio_file
        
        # Se arquivo muito grande, extrair √°udio comprimido
        if tamanho_mb > 25:
            logger.info(f"üîÑ Arquivo muito grande ({tamanho_mb:.1f}MB). Extraindo √°udio comprimido...")
            import subprocess
            
            # Criar arquivo de √°udio comprimido
            audio_comprimido = case_dir / "audio_temp.mp3"
            
            comando = [
                'ffmpeg', '-i', str(audio_file),
                '-vn',  # Sem v√≠deo
                '-acodec', 'mp3',
                '-ab', '64k',  # Bitrate baixo
                '-ar', '16000',  # Sample rate reduzido
                '-y',  # Sobrescrever
                str(audio_comprimido)
            ]
            
            logger.info(f"üé¨ Executando: {' '.join(comando[:6])}...")
            resultado = subprocess.run(comando, capture_output=True, text=True)
            
            if resultado.returncode != 0:
                logger.error(f"‚ùå Erro no ffmpeg: {resultado.stderr}")
                raise HTTPException(status_code=500, detail=f"Falha na convers√£o de √°udio: {resultado.stderr}")
            
            arquivo_para_transcricao = audio_comprimido
            tamanho_novo = arquivo_para_transcricao.stat().st_size / (1024 * 1024)
            logger.info(f"‚úÖ √Åudio comprimido: {tamanho_novo:.1f}MB")
        
        # Transcrever com Whisper
        logger.info("ü§ñ Iniciando transcri√ß√£o com OpenAI Whisper...")
        whisper_service = WhisperService()
        transcricao = whisper_service.transcrever_audiencia(arquivo_para_transcricao, case_id)
        logger.info(f"‚úÖ Transcri√ß√£o conclu√≠da! ({len(transcricao.texto_completo)} caracteres)")
        
        # Limpar arquivo tempor√°rio se criado
        if arquivo_para_transcricao != audio_file and arquivo_para_transcricao.exists():
            arquivo_para_transcricao.unlink()
            logger.info("üóëÔ∏è Arquivo tempor√°rio removido")
        
        # Salvar transcri√ß√£o
        logger.info("üíæ Salvando transcri√ß√£o...")
        whisper_service.salvar_transcricao(transcricao, case_dir)
        logger.info("‚úÖ Transcri√ß√£o salva com sucesso!")
        
        return ProcessingResponse(
            case_id=case_id,
            step="transcribe_audio",
            status="completed",
            message=f"√Åudio transcrito com sucesso. {len(transcricao.texto_completo)} caracteres."
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro na transcri√ß√£o: {str(e)}")

# ETAPA 2: Processar com Gemini
@app.post("/step2-process/{case_id}", response_model=ProcessingResponse)
async def step2_process_with_gemini(case_id: str):
    """ETAPA 2: Processa documentos e transcri√ß√£o com Gemini"""
    logger.info(f"üß† INICIANDO ETAPA 2 - PROCESSAMENTO GEMINI - Case ID: {case_id}")
    
    from services.gemini_processor import GeminiProcessor
    from services.rag_service import RAGService
    
    case_dir = STORAGE_DIR / case_id
    if not case_dir.exists():
        logger.error(f"‚ùå Case ID n√£o encontrado: {case_id}")
        raise HTTPException(status_code=404, detail="case_id n√£o encontrado")

    logger.info(f"üìÇ Diret√≥rio encontrado: {case_dir}")
    
    try:
        # Processar documento do processo
        logger.info("ü§ñ Inicializando Gemini Processor...")
        gemini_processor = GeminiProcessor()
        
        # Encontrar e processar documento
        logger.info("üîç Procurando documento do processo...")
        processo_path = None
        for ext in ALLOWED_PROCESSO:
            proc_path = case_dir / f"processo.{ext}"
            logger.info(f"   Verificando: {proc_path}")
            if proc_path.exists():
                processo_path = proc_path
                logger.info(f"‚úÖ Documento encontrado: {processo_path}")
                break

        if not processo_path:
            logger.error("‚ùå Documento do processo n√£o encontrado")
            raise HTTPException(status_code=404, detail="Documento do processo n√£o encontrado")
        
        # Extrair texto e processar
        logger.info(f"üìÑ Extraindo texto de: {processo_path.suffix}")
        
        try:
            if processo_path.suffix.lower() == '.pdf':
                doc = fitz.open(str(processo_path))
                texto_processo = ""
                for page in doc:
                    texto_processo += page.get_text("text") + "\n"
                doc.close()
            else:  # DOCX
                doc = Document(str(processo_path))
                texto_processo = '\n'.join([par.text for par in doc.paragraphs if par.text.strip()])
            
            logger.info(f"‚úÖ Texto extra√≠do: {len(texto_processo)} caracteres")
            
            # Salvar texto extra√≠do para uso posterior no di√°logo inteligente
            texto_extraido_path = case_dir / "processo_extraido.txt"
            texto_extraido_path.write_text(texto_processo, encoding='utf-8')
            logger.info(f"üíæ Texto do processo salvo: {texto_extraido_path}")
            
            # Gemini 1.5 Pro suporta at√© 2M tokens (~1.6M caracteres)
            # S√≥ truncar se for extremamente grande (acima de 1.5M chars)
            if len(texto_processo) > 1500000:
                texto_processo = texto_processo[:1500000] + "... [TEXTO TRUNCADO - MUITO GRANDE]"
                logger.info("‚úÇÔ∏è Texto truncado para 1.5M caracteres (limite pr√°tico)")
            
            logger.info("üß† Processando com Gemini...")
            
            try:
                processo_estruturado = gemini_processor.extrair_informacoes_processo(texto_processo)
                logger.info(f"‚úÖ Processamento Gemini conclu√≠do: {processo_estruturado.numero_processo}")
            except Exception as gemini_error:
                if "quota" in str(gemini_error).lower() or "429" in str(gemini_error):
                    logger.warning("‚ö†Ô∏è Quota do Gemini excedida. Usando estrutura mock para continuar o teste...")
                    
                    # Mock tempor√°rio para testar Claude
                    from services.gemini_processor import ProcessoEstruturado, ParteProcesso, PedidoProcesso, FatoRelevante
                    
                    processo_estruturado = ProcessoEstruturado(
                        numero_processo="0000398-03.2024.5.09.0010",
                        partes=[
                            ParteProcesso(nome="Jo√£o Silva", tipo="requerente", qualificacao="Trabalhador"),
                            ParteProcesso(nome="Empresa XYZ Ltda", tipo="requerida", qualificacao="Empregadora")
                        ],
                        pedidos=[
                            PedidoProcesso(descricao="Horas extras", categoria="verbas_trabalhistas", valor_estimado="R$ 15.000,00", deferido=None)
                        ],
                        fatos_relevantes=[
                            FatoRelevante(descricao="Trabalho sem registro de horas extras", fonte="inicial", impacto_decisao="Relevante para decis√£o")
                        ],
                        periodo_contratual="2020-2024",
                        valor_causa="R$ 50.000,00",
                        jurisprudencias_citadas=[],
                        decisao_final=None,
                        fundamentacao_resumida="Processo trabalhista em andamento"
                    )
                    logger.info("‚úÖ Mock do Gemini aplicado para continuar teste")
                else:
                    raise HTTPException(status_code=500, detail=f"Erro no processamento Gemini: {str(gemini_error)}")
            
        except Exception as e:
            logger.error(f"‚ùå Erro no processamento Gemini: {str(e)}")
            raise HTTPException(status_code=500, detail=f"Erro no processamento Gemini: {str(e)}")
        
        # Processar transcri√ß√£o da audi√™ncia se existir
        transcricao_path = case_dir / "audiencia_transcricao.txt"
        analise_audiencia = None
        if transcricao_path.exists():
            transcricao_texto = transcricao_path.read_text(encoding='utf-8')
            # Criar objeto TranscricaoAudiencia mock para an√°lise
            from services.whisper_service import TranscricaoAudiencia, WhisperService
            transcricao_mock = TranscricaoAudiencia(
                texto_completo=transcricao_texto,
                duracao_segundos=None,
                idioma_detectado='pt',
                confianca=None,
                segmentos=None,
                metadados={}
            )
            whisper_service = WhisperService()
            analise_audiencia = whisper_service.processar_audiencia_com_gemini(transcricao_mock, case_id)
        
        # Salvar no RAG
        rag_service = RAGService()
        rag_service.salvar_conhecimento_caso(processo_estruturado, analise_audiencia, case_id)
        
        return ProcessingResponse(
            case_id=case_id,
            step="process_gemini",
            status="completed",
            message="Documentos processados e salvos no RAG com sucesso"
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro no processamento Gemini: {str(e)}")

# ETAPA 3: Gerar senten√ßa com Claude
@app.post("/step3-generate/{case_id}", response_model=ProcessingResponse)
async def step3_generate_sentence(case_id: str):
    """ETAPA 3: Gera senten√ßa consultando RAG com Claude"""
    logger.info(f"‚úçÔ∏è INICIANDO ETAPA 3 - GERA√á√ÉO CLAUDE - Case ID: {case_id}")
    
    from services.claude_service import ClaudeService
    from services.rag_service import RAGService
    
    case_dir = STORAGE_DIR / case_id
    if not case_dir.exists():
        logger.error(f"‚ùå Case ID n√£o encontrado: {case_id}")
        raise HTTPException(status_code=404, detail="case_id n√£o encontrado")

    logger.info(f"üìÇ Diret√≥rio encontrado: {case_dir}")
    
    try:
        # Consultar conhecimento no RAG
        logger.info("üìö Consultando conhecimento no RAG...")
        rag_service = RAGService()
        conhecimento_caso = rag_service.recuperar_conhecimento_caso(case_id)
        logger.info(f"‚úÖ Conhecimento recuperado: {len(str(conhecimento_caso))} caracteres")
        
        # Gerar senten√ßa com Claude
        logger.info("ü§ñ Iniciando gera√ß√£o de senten√ßa com Claude...")
        claude_service = ClaudeService()
        sentenca = claude_service.gerar_sentenca_com_rag(conhecimento_caso, case_id)
        logger.info(f"‚úÖ Senten√ßa gerada! ({len(sentenca)} caracteres)")
        
        # Salvar senten√ßa
        logger.info("üíæ Salvando senten√ßa...")
        sentenca_path = case_dir / "sentenca.txt"
        sentenca_path.write_text(sentenca, encoding='utf-8')
        logger.info(f"‚úÖ Senten√ßa salva: {sentenca_path}")
        logger.info("üéâ ETAPA 3 CONCLU√çDA! Senten√ßa gerada com sucesso!")
        
        return ProcessingResponse(
            case_id=case_id,
            step="generate_sentence",
            status="completed",
            message="Senten√ßa gerada com sucesso"
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro na gera√ß√£o da senten√ßa: {str(e)}")

@app.get("/download/{case_id}/sentenca")
async def download_sentence(case_id: str):
    """Download da senten√ßa gerada.
    Aceita tanto 'sentenca.txt' (etapa 3) quanto 'sentenca_gerada.txt' (pipeline autom√°tico).
    """
    case_dir = STORAGE_DIR / case_id
    path_options = [case_dir / "sentenca.txt", case_dir / "sentenca_gerada.txt"]
    sentenca_path = next((p for p in path_options if p.exists()), None)

    if not sentenca_path:
        raise HTTPException(status_code=404, detail="Senten√ßa n√£o encontrada")

    return FileResponse(
        str(sentenca_path),
        media_type="text/plain",
        filename=f"sentenca_{case_id}.txt"
    )

@app.post("/generate-from-existing/{case_id}", response_model=ProcessingResponse)
async def generate_from_existing(case_id: str):
    """Gera senten√ßa usando arquivos j√° existentes (sem reprocessar APIs).

    Usa 'processo_extraido.txt' e, se existir, 'transcricao.json' ou 'audiencia_transcricao.txt'.
    """
    import json
    from services.intelligent_dialogue_service import IntelligentDialogueService

    case_dir = STORAGE_DIR / case_id
    if not case_dir.exists():
        raise HTTPException(status_code=404, detail="case_id n√£o encontrado")

    # Carregar processo extra√≠do
    processo_path = case_dir / "processo_extraido.txt"
    if not processo_path.exists():
        raise HTTPException(status_code=404, detail="processo_extraido.txt n√£o encontrado")
    texto_processo = processo_path.read_text(encoding='utf-8')

    # Carregar transcri√ß√£o (opcional)
    transcricao_audiencia = None
    transcricao_json = case_dir / "transcricao.json"
    transcricao_txt = case_dir / "audiencia_transcricao.txt"
    if transcricao_json.exists():
        data = json.loads(transcricao_json.read_text(encoding='utf-8'))
        transcricao_audiencia = data.get('texto_completo') or None
    elif transcricao_txt.exists():
        transcricao_audiencia = transcricao_txt.read_text(encoding='utf-8')

    # Executar di√°logo inteligente (usa RAG avan√ßado setorial internamente)
    dialogue_service = IntelligentDialogueService(case_id)
    resultado_completo = dialogue_service.executar_dialogo_completo(
        texto_processo=texto_processo,
        transcricao_audiencia=transcricao_audiencia
    )

    # Salvar
    resultado_path = case_dir / "dialogo_resultado_completo.json"
    resultado_path.write_text(
        json.dumps(resultado_completo, indent=2, ensure_ascii=False),
        encoding='utf-8'
    )

    sentenca_final = resultado_completo.get("sentenca_final", "")
    if sentenca_final:
        (case_dir / "sentenca_gerada.txt").write_text(sentenca_final, encoding='utf-8')

    return ProcessingResponse(
        case_id=case_id,
        step="generate_from_existing",
        status="completed",
        message="Gera√ß√£o conclu√≠da a partir de arquivos existentes"
    )

@app.post("/init-style/{case_id}", response_model=ProcessingResponse)
async def init_style_from_examples(case_id: str, max_docs: int = 30):
    """Inicializa o estilo da ju√≠za para o caso usando senten√ßas modelos locais.

    Varre diret√≥rios 'Senten√ßas_2023', 'Senten√ßas_2024', 'Senten√ßas_2025' e carrega o texto
    de arquivos .docx e .pdf como exemplos de estilo no RAG isolado do caso.
    """
    from services.enhanced_rag_service import EnhancedRAGService
    sentences_root = Path(__file__).resolve().parent.parent
    folders = [
        sentences_root / "Senten√ßas_2023",
        sentences_root / "Senten√ßas_2024",
        sentences_root / "Senten√ßas_2025",
    ]

    samples: list[str] = []

    def read_docx(path: Path) -> str:
        try:
            if Document is None:
                return ""
            doc = Document(str(path))
            text = "\n".join(p.text for p in doc.paragraphs if p.text.strip())
            return text
        except Exception:
            return ""

    def read_pdf(path: Path) -> str:
        try:
            if fitz is None:
                return ""
            doc = fitz.open(str(path))
            text = "\n".join(page.get_text("text") for page in doc)
            doc.close()
            return text
        except Exception:
            return ""

    for folder in folders:
        if not folder.exists():
            continue
        for file in folder.iterdir():
            if not file.is_file():
                continue
            ext = file.suffix.lower()
            content = ""
            if ext == ".docx":
                content = read_docx(file)
            elif ext == ".pdf":
                content = read_pdf(file)
            # .doc n√£o suportado diretamente por python-docx; ignorar por ora

            if content:
                # Normalizar e limitar tamanho por documento para n√£o estourar mem√≥ria
                content = content.strip()
                if len(content) > 20000:
                    content = content[:20000]
                samples.append(content)

            if len(samples) >= max_docs:
                break
        if len(samples) >= max_docs:
            break

    if not samples:
        raise HTTPException(status_code=404, detail="Nenhuma senten√ßa modelo encontrada (.docx/.pdf)")

    rag = EnhancedRAGService(case_id)
    rag.initialize_judge_style(samples, force_reload=True)

    return ProcessingResponse(
        case_id=case_id,
        step="init_style",
        status="completed",
        message=f"Estilo inicializado com {len(samples)} documentos"
    )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)